# ğŸš€ InsightBot

![Project Poster](./images/poster.png)
Automated News Analytics & Visualization System

![Python](https://img.shields.io/badge/Python-3.10%2B-blue)
![MongoDB](https://img.shields.io/badge/Database-MongoDB-green)
![Streamlit](https://img.shields.io/badge/UI-Streamlit-orange)
![PowerBI](https://img.shields.io/badge/Dashboard-PowerBI-yellow)
![License: MIT](https://img.shields.io/badge/License-MIT-purple)

---

## ğŸ“‘ Table of Contents

* [Description](#description)
* [Features](#features)
* [Tech Stack](#tech-stack)
* [Getting Started](#getting-started)
* [Usage](#usage)
* [Screenshots](#screenshots)
* [License](#license)

---

## ğŸ’¡ Blog

[Medium Blog: InsightBot â€“ Simplifying Daily News with Data Science & Visualization](https://medium.com/@dsdataminds/insightbot-simplifying-daily-news-with-data-science-visualization-455ba5cfdde2)

---

## ğŸ“ Description

*InsightBot* is an automated news scraping and analytics system designed to collect, process, and visualize news from *30+ websites*.
It delivers structured insights with multilingual support and interactive dashboards.

Main workflow:

1. *Data Collection* â†’ Scrape news & articles from multiple sources.
2. *Data Cleaning & Processing* â†’ Structure and preprocess data.
3. *Modeling & Analysis* â†’ Extract *topics*, generate *headlines*, detect *languages*.
4. *Data Storage* â†’ Save processed data in *MongoDB*.
5. *User Interface* â†’ Explore via *Streamlit* (Admin & User roles).
6. *Reporting & Visualization* â†’ Advanced insights through *Power BI* dashboards.

> ğŸ’¡ InsightBot helps organizations monitor news, extract insights, and visualize trends in real-time.

---

## ğŸ”„ Workflow

![Workflow](./images/InsightBot_flow.png)

---

## ğŸ“Š Features

* ğŸ”„ Automated scraping of 30+ news websites
* ğŸ§  Topic extraction & context classification
* ğŸŒ Multi-language detection & headline generation
* ğŸ’¾ MongoDB integration for efficient data storage
* ğŸ¨ Streamlit-based interactive interface (admin & user roles)
* ğŸ“ˆ Power BI dashboards for advanced reporting
* ğŸ” Secure authentication (login/register)
* âš™ Workflow orchestration with *Perfect*

---

## âš™ Tech Stack

* *Python* â†’ Scraping, cleaning, NLP modeling
* *Libraries* â†’ Pandas, BeautifulSoup / Scrapy, NLP models
* *Database* â†’ MongoDB
* *Frontend* â†’ Streamlit
* *Visualization* â†’ Power BI
* *Orchestration* â†’ Perfect

---

## âš™ Installation Guide

1. Clone repository:

```bash
git clone <repo-url>
cd InsightBot
```

2. Create virtual environment:

```bash
python -m venv .venv
source .venv/bin/activate   # Linux/Mac
.venv\Scripts\activate      # Windows
```

3. Install requirements:

```bash
pip install -r requirements.txt
```

---

## ğŸ—„ MongoDB Setup

1. Start your MongoDB service (local or remote).

2. Run initialization script:

```bash
python init_schema.py
```

3. Seed default data:

```bash
python seed_data.py
```

4. Import sample articles (choose one option):

### â–¶ Regular Import (simple add)

```powershell
& "C:\Program Files\MongoDB\tools\bin\mongoimport.exe" `
  --db insightbot `
  --collection articles `
  --type csv `
  --file "C:\Users\moham\Desktop\Insightbot\Interface\insightbot_seed\news_articles.csv" `
  --headerline
```

### â–¶ Re-import / Update Without Duplicates

```powershell
& "C:\Program Files\MongoDB\tools\bin\mongoimport.exe" `
  --db insightbot `
  --collection articles `
  --type csv `
  --file "C:\Users\moham\Desktop\Insightbot\Interface\insightbot_seed\news_articles.csv" `
  --headerline `
  --upsert `
  --upsertFields id
```

### â–¶ Full Reset Import (Clean Slate)

```powershell
& "C:\Program Files\MongoDB\tools\bin\mongoimport.exe" `
  --db insightbot `
  --collection articles `
  --type csv `
  --file "C:\Users\moham\Desktop\Insightbot\Interface\insightbot_seed\news_articles.csv" `
  --headerline `
  --drop
```

---

## âš¡ Perfect Pipeline

1. Start Perfect server (optional for orchestration UI):

```bash
Perfect server start
```

2. Run the Perfect flow to orchestrate scraping and processing:

```bash
python flows/pipeline.py
```

3. Monitor and manage pipeline runs via Perfect UI at [http://localhost:4200](http://localhost:4200).

---

## â–¶ Running the Application

```bash
streamlit run app.py
```

Open in browser: [http://localhost:8501](http://localhost:8501)

---

## ğŸ§± Database Schema

Collections:

* *users* â†’ username, email, password_hash, role, is_approved, join_date, time_spent_minutes
* *logs* â†’ ts, user, event, meta
* *articles* â†’ id, title, content, source, language, context, sentiment, url, fetched_at, t_total_sec
* *app_store* â†’ key, value

Indexes are defined in `init_schema.py`.

---

## ğŸ‘¤ Usage

* *Admin* â†’ Manage users, monitor dashboards, oversee system
* *User* â†’ Register/login to view personalized news & dashboards

---

## ğŸŒŸ Features

### âœ… User Dashboard

* Browse articles with filters: date, language, sentiment, context, search
* Export results to CSV
* View analytics charts: articles over time, articles by source, sentiment distribution, heatmap
* Open article view + recommendations
* Pagination for articles

### âœ… Admin Panel

* KPI cards (Total Users, Logins, Reads, Total Articles, Pending Approvals, Fetch Jobs)
* Visualizations (activity trend, reads by context, ingestion rhythm, top users by time spent)
* User management (add/update/approve/reject users)

---

## ğŸ” Authentication & Security

* Passwords are hashed with *bcrypt*
* Only *approved users* can log in
* Admin role required for Admin Panel
* Unique constraints on usernames and emails

---

## ğŸ“Š KPIs & Visualizations

* *User Dashboard*: articles over time, top sources, sentiment distribution, heatmap
* *Admin Panel*: activity trend, reads by context, articles per hour, top users

---

## ğŸŒ± Default Data & Seeding

* *Admin user*:

  * Username: admin
  * Password: admin123
* *App store defaults*: last_page = dashboard, app_version = 1.0.0

---

## ğŸ“¸ Screenshots

### Streamlit Interface

![Interface](./images/interface.png)

### Power BI Dashboard

![Dashboard](./images/report.png)

---

## ğŸ“œ License

This project is licensed under the *MIT License*.
